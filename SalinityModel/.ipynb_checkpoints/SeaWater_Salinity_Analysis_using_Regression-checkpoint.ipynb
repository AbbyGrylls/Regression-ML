{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df704fe-d585-49e1-8d89-168ac1942fc8",
   "metadata": {},
   "source": [
    "# Oceanographic Data Analysis using Regression\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "We aim to explore and analyze oceanographic data collected from various depths in the Pacific Ocean. The focus is to investigate how physical parameters such as **temperature**, **depth**, **salinity**, **oxygen concentration**, and **density** are related. Understanding these relationships is important for modeling ocean behavior and its impact on marine ecosystems and climate.\n",
    "\n",
    "## Solution Approach\n",
    "\n",
    "- Load a subset of the original `bottle.csv` dataset (trimmed to 1215 rows for performance and some rows are erased for data refining).\n",
    "- Extract and convert relevant oceanographic parameters to NumPy arrays.\n",
    "- Perform initial data exploration by printing samples of each parameter.\n",
    "- Further analysis (e.g., regression, correlation, visualization) will be built on this structured data.\n",
    "\n",
    "## Dataset Source\n",
    "\n",
    "This notebook uses a trimmed version of the original dataset from Kaggle:  \n",
    "[CalCOFI Bottle Data](https://www.kaggle.com/datasets/sohier/calcofi)\n",
    "\n",
    " File used: `bottle.csv` (first 1215 rows from `bottle.csv`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3f132-94f3-45cf-9268-0ecf14be0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8d8f2-47b9-4784-adb9-cbb47e08d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('bottle.csv', low_memory=False)\n",
    "\n",
    "# Extract relevant columns as numpy arrays\n",
    "Temperature = df['T_degC'].to_numpy()[:1215] \n",
    "Depth = df['Depthm'].to_numpy()[:1215] \n",
    "Oxygen = df['O2ml_L'].to_numpy()[:1215] \n",
    "Density = df['STheta'].to_numpy()[:1215] \n",
    "Salinity = df['Salnty'].to_numpy()[:1215]\n",
    "\n",
    "print(\"Temperature:\", Temperature[:10])\n",
    "print(\"Depth:\", Depth[:10])\n",
    "print(\"Oxygen:\", Oxygen[:10])\n",
    "print(\"Density:\", Density[:10])\n",
    "print(\"Salinity:\", Salinity[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b1f89-0b26-4cca-9b25-029583ff4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine selected features into a single matrix\n",
    "# Oxygen data is excluded becuase of no data and for simplicity\n",
    "X = np.column_stack([Temperature, Depth, Density])  # shape: (1215, 3)\n",
    "\n",
    "# Feature scaling: standardizing inputs: [important] Cost value will be e33 because of depth being too large than other features\n",
    "means = X.mean(axis=0)\n",
    "stds = X.std(axis=0)\n",
    "X = (X - means) / stds  # Normalize each feature to mean 0, std 1\n",
    "\n",
    "# Target variable\n",
    "y = Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697b2e3-b614-4aa4-97de-8c9b1009623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes Mean Squared Error cost\n",
    "def compute_cost(X, y, w, b, m):\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(X[i], w) + b  # predicted value\n",
    "        cost += (f_wb_i - y[i]) ** 2  # squared error\n",
    "    return cost / (2 * m)  # mean cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e680b-74a4-42ee-b0cb-5dbbc1b2a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes gradient of the cost function with respect to weights and bias\n",
    "def compute_grad(X, y, w, b, m, n):\n",
    "    dw = np.zeros((n,))\n",
    "    db = 0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(X[i], w) + b\n",
    "        err = f_wb_i - y[i]\n",
    "        for j in range(n):\n",
    "            dw[j] += err * X[i][j]\n",
    "        db += err\n",
    "    return dw / m, db / m  # average gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a088fa7-5c98-467d-b700-81a77e1bf612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs batch gradient descent to learn weights and bias\n",
    "def grad_des(X, y, w, b, iter=100, alpha=0.0001):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    J_history = []\n",
    "    p_history = []\n",
    "\n",
    "    for i in range(iter):\n",
    "        dw, db = compute_grad(X, y, w, b, m, n)\n",
    "        w -= alpha * dw\n",
    "        b -= alpha * db\n",
    "        J_history.append(compute_cost(X, y, w, b, m))\n",
    "        p_history.append((w.copy(), b))\n",
    "\n",
    "        # Print progress every 10 iterations\n",
    "        if i % 10 == 0 or i == iter - 1:\n",
    "            print(f\"Iteration {i:4}: Cost {J_history[-1]:.4f}, \"\n",
    "                  f\"dj_dw: {dw}, dj_db: {db:.4f}, \"\n",
    "                  f\"w: {w}, b: {b:.4f}\")\n",
    "    return w, b, J_history, p_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b101a-3717-4307-9ad7-c80436a275b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "w = np.zeros(X.shape[1])\n",
    "b = 0\n",
    "\n",
    "# Run gradient descent\n",
    "w, b, J_history, p_history = grad_des(X, y, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674f914-eb46-4761-b266-ab03a4423662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weights and bias history\n",
    "w_history = np.array([p[0] for p in p_history])\n",
    "b_history = [p[1] for p in p_history]\n",
    "\n",
    "# Plot evolution of each weight and bias\n",
    "plt.figure()\n",
    "for i in range(w_history.shape[1]):\n",
    "    plt.plot(w_history[:, i], label=f'w[{i}]')\n",
    "plt.plot(b_history, label='b')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Weights and Bias over Iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c31d2b-a414-4f75-ba32-4036ada39895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plot of cost vs first two weights (w[0], w[1])\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(w_history[:, 0], w_history[:, 1], J_history, marker='o', color='blue', label='Gradient Descent Path')\n",
    "ax.set_xlabel('w[0]')\n",
    "ax.set_ylabel('w[1]')\n",
    "ax.set_zlabel('Cost (J)')\n",
    "ax.set_title('3D Plot of Cost vs w[0] and w[1]')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ef224-fabe-45e0-99ed-5a930712d0c0",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "- **Missing data** in CSV can introduce `NaN` if we incorrectly replace missing with 0.\n",
    "- **Decreasing learning rate (`alpha`)** helps cost converge more steadily.\n",
    "- **Feature scaling** is critical: without it, large-magnitude features (e.g., Depth) dominate and cause cost divergence.\n",
    "- Final cost remained around ~500 â€” improvement possible.\n",
    "\n",
    "### Potential Improvements\n",
    "\n",
    "- Try polynomial features or nonlinear transformations.\n",
    "- Apply regularization to prevent overfitting.\n",
    "- Include Oxygen as a feature and check correlation: More feature engg is required.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
